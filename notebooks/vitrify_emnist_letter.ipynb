{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vitrify for the EMNIST-Letter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Untie local dependency\n",
    "cwd = os.getcwd().split(\"/\")\n",
    "local_repo_path = \"/\".join(cwd[:-1])\n",
    "sys.path.insert(0, local_repo_path)\n",
    "\n",
    "from src.models.multi_layer_perceptron import MultiLayerPerceptron\n",
    "from src.models.soft_decision_tree import SoftBinaryDecisionTree\n",
    "from src.models.variational_autoencoder import VariationalAutoEncoder\n",
    "from src.models.convolutional_dnn import ConvDNN\n",
    "from src.data.make_dataset import load_data, join_data\n",
    "from src.visualization.visualize import draw_tree\n",
    "from src.utils import balanced_sample_maker\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the EMNIST-Letter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data (To download data from scratch, set already_downloaded=False)\n",
    "data = load_data(dataset=\"EMNIST_Letter\", already_downloaded=True)\n",
    "\n",
    "# Get the number of input features\n",
    "n_rows, n_cols = np.shape(data[\"x_train\"])[1:]\n",
    "n_features = n_rows * n_cols\n",
    "n_classes = np.unique(data[\"y_train\"]).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the structure of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_one_hot  ==> (104000, 26)\n",
      "x_test_flat  ==> (20800, 784)\n",
      "x_train  ==> (104000, 28, 28)\n",
      "x_test  ==> (20800, 28, 28)\n",
      "y_train  ==> (104000,)\n",
      "y_test_one_hot  ==> (20800, 26)\n",
      "y_test  ==> (20800,)\n",
      "x_valid  ==> (20800, 28, 28)\n",
      "y_valid  ==> (20800,)\n",
      "y_valid_one_hot  ==> (20800, 26)\n",
      "x_valid_flat  ==> (20800, 784)\n",
      "x_train_flat  ==> (104000, 784)\n"
     ]
    }
   ],
   "source": [
    "for key, array in data.items():\n",
    "    print(key, \" ==>\", np.shape(array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the **data** variable is a dictionary, consisting of numpy arrays. Above we can see the shapes of the EMNIST-Letter data in our dictionary. We can also inspect the other variables we created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows:  28\n",
      "n_cols:  28\n",
      "n_features:  784\n",
      "n_classes:  26\n"
     ]
    }
   ],
   "source": [
    "print(\"n_rows: \", n_rows)\n",
    "print(\"n_cols: \", n_cols)\n",
    "print(\"n_features: \", n_features)\n",
    "print(\"n_classes: \", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise the training data with their labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_to_plot = 9\n",
    "random_indices = np.random.choice(range(104000), images_to_plot)\n",
    "\n",
    "sample_images = data[\"x_train_flat\"][random_indices, :]\n",
    "sample_labels = data[\"y_train\"][random_indices]\n",
    "\n",
    "plt.clf()\n",
    "plt.style.use(\"seaborn-muted\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, \n",
    "                         figsize=(5,5),\n",
    "                         sharex=True, sharey=True,\n",
    "                         subplot_kw=dict(aspect=\"equal\"))\n",
    "\n",
    "for i in range(images_to_plot):\n",
    "    \n",
    "    subplot_row = i // 3 \n",
    "    subplot_col = i % 3  \n",
    "    ax = axes[subplot_row, subplot_col]\n",
    "\n",
    "    plottable_image = np.reshape(sample_images[i, :], (28, 28))\n",
    "    ax.imshow(plottable_image, cmap=\"gray_r\")\n",
    "    \n",
    "    ax.set_title(\"Digit Label: {}\".format(sample_labels[i]))\n",
    "    ax.set_xbound([0, 28])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, in summary, our training data (**\"x_train\"**) consists of 104000 28x28 images of upper- and lowercase letters, with the labels saying what letter the image depicts (**\"y_train\"**). We also have a flattend version of the images (**\"x_train_flat\"**) and one-hot encoded labels (**\"y_train_one_hot\"**). This is the same for our validation and test data, both consisting of 20800 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Train the VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start off by initialising the VAE model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VAE\n",
    "vae = VariationalAutoEncoder(\n",
    "    name = \"vae_emnist_letter\",\n",
    "    num_inputs = n_features,\n",
    "    # If true, training info is outputted to stdout\n",
    "    keras_verbose = False,\n",
    "    # A summary of the NN is printed to stdout\n",
    "    print_model_summary = False,\n",
    "    # Size of latent dimension\n",
    "    latent_dim = 20,\n",
    "    # Specify the encoder layers [units, activation, dropout, l2, bias]\n",
    "    encoder_layers = [\n",
    "        [512, \"relu\", 0.0, 0.0, True, \"gaussian\"],\n",
    "        [256, \"relu\", 0.0, 0.0, True, \"gaussian\"],\n",
    "        [128, \"relu\", 0.0, 0.0, True, \"gaussian\"]\n",
    "    ],\n",
    "    # Specify the decoder layers [units, activation, dropout, l2, bias]\n",
    "    decoder_layers = [\n",
    "        [128, \"relu\", 0.0, 0.0, True, \"gaussian\"],\n",
    "        [256, \"relu\", 0.0, 0.0, True, \"gaussian\"],\n",
    "        [512, \"relu\", 0.0, 0.0, True, \"gaussian\"]\n",
    "    ],\n",
    "    # The final output layer's activation function\n",
    "    final_activation = \"sigmoid\",\n",
    "    # The maximum number of epochs to run\n",
    "    epochs = 100,\n",
    "    # The batch size to use in the VAE\n",
    "    batch_size = 128,\n",
    "    # The learning rate used in optimisation\n",
    "    learning_rate = 0.001,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train our model. By setting `load_model=True`, we load a previously trained model. If you want to train the VAE model from scratch, set `load_model=False`. The VAE does not receive any target data, seeing as it is not trying to predict the labels, but rather trying to reconstruct its input. Thus, we only pass the flattened training and validation data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vae_emnist_letter model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train VAE\n",
    "vae.train(data[\"x_train_flat\"], data[\"x_valid_flat\"], load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: Nan | loss: 157.2493401512733\n"
     ]
    }
   ],
   "source": [
    "# Evaluate VAE\n",
    "vae_results = vae.evaluate(data[\"x_test_flat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our trained VAE model, we can generate new data. Here, we generate 30000 additional data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Generate new data\n",
    "x_gen_flat = vae.sample(30000)\n",
    "print(np.shape(x_gen_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualise some results from our VAE model and the generated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape to images\n",
    "x_gen = np.array([np.reshape(x_gen_flat[i], [n_rows, n_cols]) for i in range(len(x_gen_flat))])\n",
    "\n",
    "images_to_plot = 9\n",
    "random_indices = np.random.choice(range(30000), images_to_plot)\n",
    "\n",
    "sample_images = x_gen[random_indices, :]\n",
    "\n",
    "plt.clf()\n",
    "plt.style.use(\"seaborn-muted\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, \n",
    "                         figsize=(5,5),\n",
    "                         sharex=True, sharey=True,\n",
    "                         subplot_kw=dict(aspect=\"equal\"))\n",
    "\n",
    "for i in range(images_to_plot):\n",
    "    \n",
    "    subplot_row = i // 3 \n",
    "    subplot_col = i % 3  \n",
    "    ax = axes[subplot_row, subplot_col]\n",
    "\n",
    "    plottable_image = np.reshape(sample_images[i, :], (28, 28))\n",
    "    ax.imshow(plottable_image, cmap=\"gray_r\")\n",
    "    \n",
    "    ax.set_xbound([0, 28])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see some of the generated images from our VAE model. They are still unlabelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Train the MLP and CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start off by initialising the MLP model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLP\n",
    "mlp = MultiLayerPerceptron(\n",
    "    name = \"mlp_emnist_letter\",\n",
    "    num_inputs = n_features,\n",
    "    num_outputs = n_classes,\n",
    "    # If true, training info is outputted to stdout\n",
    "    keras_verbose = False,\n",
    "    # A summary of the NN is printed to stdout\n",
    "    print_model_summary = False,\n",
    "    # ff_layers = [units, activation, regularization, dropout, use_bias]\n",
    "    ff_layers = [\n",
    "        [512, \"relu\", 0.0, 0.2, True, \"gaussian\"],\n",
    "        [512, \"relu\", 0.0, 0.2, True, \"gaussian\"],\n",
    "        [512, \"relu\", 0.0, 0.2, True, \"gaussian\"],\n",
    "        [512, \"relu\", 0.0, 0.2, True, \"gaussian\"]\n",
    "    ],\n",
    "    # The final output layer's activation function\n",
    "    final_activation = \"softmax\",\n",
    "    # The objective function for the NN\n",
    "    objective = \"categorical_crossentropy\",\n",
    "    # The maximum number of epochs to run\n",
    "    epochs = 40,\n",
    "    # The batch size to use in the NN\n",
    "    batch_size = 64,\n",
    "    # The learning rate used in optimization\n",
    "    learning_rate = 0.001,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same format as with the VAE applies, except here we provide the model with the necessary targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mlp_emnist_letter model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train MLP\n",
    "mlp.train(\n",
    "    data[\"x_train_flat\"], data[\"y_train_one_hot\"],\n",
    "    data[\"x_valid_flat\"], data[\"y_valid_one_hot\"], load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.44% | loss: 0.33771701676856675\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP\n",
    "mlp_results = mlp.evaluate(data[\"x_test_flat\"], data[\"y_test_one_hot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLP model achieved an accuracy of 91.44% on the test set. Next, we do the same for the CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN\n",
    "cnn = ConvDNN(\n",
    "    name = \"cnn_emnist_letter\",\n",
    "    img_rows = n_rows,\n",
    "    img_cols = n_cols,\n",
    "    num_outputs = n_classes,\n",
    "    # If true, training info is outputted to stdout\n",
    "    keras_verbose = False,\n",
    "    # A summary of the NN is printed to stdout\n",
    "    print_model_summary = False,\n",
    "    # Convolutional layers\n",
    "    conv_layers = [\n",
    "        [\"conv2d\", 64, (3, 3), (1, 1), \"valid\", \"relu\", True, 0.0, 0.0, 0.0, 0.2],\n",
    "        [\"conv2d\", 64, (3, 3), (1, 1), \"valid\", \"relu\", True, 0.0, 0.0, 0.0, 0.2],\n",
    "        [\"max_pool2d\", (2, 2), None, \"valid\", 0.0],\n",
    "        [\"conv2d\", 64, (3, 3), (1, 1), \"valid\", \"relu\", True, 0.0, 0.0, 0.0, 0.2],\n",
    "        [\"conv2d\", 64, (3, 3), (1, 1), \"valid\", \"relu\", True, 0.0, 0.0, 0.0, 0.2],\n",
    "        [\"max_pool2d\", (2, 2), None, \"valid\", 0.0],\n",
    "    ],\n",
    "    # ff_layers = [units, activation, regularization, dropout, use_bias]\n",
    "    ff_layers = [\n",
    "        [512, \"relu\", 0.0, 0.2, True, \"normal\"],\n",
    "        [512, \"relu\", 0.0, 0.2, True, \"normal\"]\n",
    "    ],\n",
    "    # The final output layer's activation function\n",
    "    final_activation = \"softmax\",\n",
    "    # The objective function for the NN\n",
    "    objective = \"categorical_crossentropy\",\n",
    "    # The maximum number of epochs to run\n",
    "    epochs = 20,\n",
    "    # The batch size to use in the NN\n",
    "    batch_size = 128,\n",
    "    # The learning rate used in optimization\n",
    "    learning_rate = 0.001,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CNN model, we do not use the flattened training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cnn_emnist_letter model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train CNN\n",
    "cnn.train(\n",
    "    data[\"x_train\"], data[\"y_train_one_hot\"],\n",
    "    data[\"x_valid\"], data[\"y_valid_one_hot\"], load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 94.35% | loss: 0.16695101275753516\n"
     ]
    }
   ],
   "source": [
    "# Evaluate CNN\n",
    "cnn_results = cnn.evaluate(data[\"x_test\"], data[\"y_test_one_hot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN model outperformed the standard MLP model, achieving an accuracy of 94.35% on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Produce soft targets for our interpretable model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use our trained CNN model to:\n",
    "1. Relabel our original training data, **x_train**\n",
    "2. Give labels to our unlabelled, generated data, **x_gen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CNN labels\n",
    "y_cnn_train = cnn.predict(data[\"x_train\"])\n",
    "y_gen = cnn.predict(x_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine both the original training data and the generated data, as well as their new soft target labels, and shuffle them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_both ==> (134000, 784)\n",
      "y_both ==> (134000, 26)\n"
     ]
    }
   ],
   "source": [
    "# Combine x_train and x_gen\n",
    "x_both = join_data([data[\"x_train\"], x_gen])\n",
    "\n",
    "# Flatten them to use it with our interpretable model\n",
    "x_both = x_both.reshape((x_both.shape[0], -1))\n",
    "\n",
    "# Combine y_cnn_train and y_gen\n",
    "y_both = join_data([y_cnn_train, y_gen])\n",
    "\n",
    "# Shuffle the data\n",
    "x_both, y_both = shuffle(x_both, y_both)\n",
    "\n",
    "print(\"x_both ==>\", np.shape(x_both))\n",
    "print(\"y_both ==>\", np.shape(y_both))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have increased our training data from 104000 samples to 134000, where each sample now has a soft target produced by the CNN model, which we are going to approximate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Train our interpretable model, the SDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of comparison, we will train three separate models:\n",
    "1. SDT using only the original data with original hard targets.\n",
    "2. SDT using only the original data with new soft targets (provided by the CNN in the third stage).\n",
    "3. SDT using the generated and the original data with soft targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) SDT using only the original data with original hard targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SDT\n",
    "sdt_raw = SoftBinaryDecisionTree(\n",
    "    name = \"sdt_raw_emnist_letter\",\n",
    "    num_inputs = n_features,\n",
    "    num_outputs = n_classes,\n",
    "    # If true, training info is outputted to stdout\n",
    "    keras_verbose = False,\n",
    "    # A summary of the NN is printed to stdout\n",
    "    print_model_summary = False,\n",
    "    # Hyperparameters\n",
    "    max_depth = 6,\n",
    "    penalty_strength = 1e+1,\n",
    "    penalty_decay = 0.5,\n",
    "    inv_temp = 0.01,\n",
    "    ema_win_size = 1000,\n",
    "    # The learning rate used in optimization\n",
    "    learning_rate = 1e-03,\n",
    "    epochs = 40,\n",
    "    batch_size = 4,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:\n",
    "- `max_depth`: the maximum depth of the tree in terms of its inner nodes. This excludes leaves.\n",
    "- `penalty_strength`: regularisation penalty strength.\n",
    "- `penalty_decay`: regularisation penalty decay as a function of depth.\n",
    "- `inv_temp`: scale the logits of the inner nodes to avoid very soft decisions.\n",
    "- `ema_win_size`: scaling factor to the default size of the window used to calculate moving averages (growing exponentially with depth) of node and path probabilities.\n",
    "- `batch_size`: we use a small one, because with increasing depth and thus a large amount of leaf bigots, larger batch sizes cause their loss terms to be scaled down too much by averaging, which results in poor optimisation properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built tree has 64 leaves out of 127 nodes\n",
      "INFO:tensorflow:Restoring parameters from /home/zander/thesis/vitrify/models/sdt_raw_emnist_letter/sdt_raw_emnist_letter\n",
      "Loaded sdt_raw_emnist_letter model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train SDT RAW\n",
    "sdt_raw.train(\n",
    "    data[\"x_train_flat\"], data[\"y_train_one_hot\"],\n",
    "    data[\"x_valid_flat\"], data[\"y_valid_one_hot\"], load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 62.89% | loss: 53.74929987687331\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SDT RAW\n",
    "sdt_raw_results = sdt_raw.evaluate(data[\"x_test_flat\"], data[\"y_test_one_hot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy of our SDT model trained on the original data and labels is 62.89%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) SDT using only the original data with new soft targets (provided by the CNN in the third stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SDT CNN\n",
    "sdt_cnn = SoftBinaryDecisionTree(\n",
    "    name = \"sdt_cnn_emnist_letter\",\n",
    "    num_inputs = n_features,\n",
    "    num_outputs = n_classes,\n",
    "    max_depth = 6,\n",
    "    penalty_strength = 1e+1,\n",
    "    penalty_decay = 0.5,\n",
    "    inv_temp = 0.01,\n",
    "    ema_win_size = 1000,\n",
    "    # The learning rate used in optimization\n",
    "    learning_rate = 1e-03,\n",
    "    epochs = 40,\n",
    "    batch_size = 4,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train this model with the soft targets from the CNN, but still use the hard targets in validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built tree has 64 leaves out of 127 nodes\n",
      "INFO:tensorflow:Restoring parameters from /home/zander/thesis/vitrify/models/sdt_cnn_emnist_letter/sdt_cnn_emnist_letter\n",
      "Loaded sdt_cnn_emnist_letter model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train SDT CNN\n",
    "sdt_cnn.train(\n",
    "    data[\"x_train_flat\"], y_cnn_train,\n",
    "    data[\"x_valid_flat\"], data[\"y_valid_one_hot\"], load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 59.70% | loss: 57.76407076395475\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SDT CNN\n",
    "sdt_cnn_results = sdt_cnn.evaluate(data[\"x_test_flat\"], data[\"y_test_one_hot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the soft targets, we did not manage to increase upon the accuracy of our SDT model trained on the hard labels. This can be attributed to the complex model (CNN) misclassifying the data almost 6% of the time, providing incorrect labels to the data. It should be noted that that we set the maximum number of epochs to 40 for all SDT models. With the other two datasets (MNIST and Fashion-MNIST), the early stopping callback mechanism stopped the models before the the 40 epochs were reached, since the validation loss and accuracy became stagnant. On the EMNIST-Letter dataset, the SDT models kept on improving, albeit slowly, but stopped training after 40 epochs. With a depth of 6, the visualisations became unfeasible to plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) SDT using the generated and the original data with soft targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SDT VAE\n",
    "sdt_vae = SoftBinaryDecisionTree(\n",
    "    name = \"sdt_cnn_vae_emnist_letter\",\n",
    "    num_inputs = n_features,\n",
    "    num_outputs = n_classes,\n",
    "    max_depth = 6,\n",
    "    penalty_strength = 1e+1,\n",
    "    penalty_decay = 0.5,\n",
    "    inv_temp = 0.01,\n",
    "    ema_win_size = 1000,\n",
    "    # The learning rate used in optimization\n",
    "    learning_rate = 1e-03,\n",
    "    epochs = 40,\n",
    "    batch_size = 4,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built tree has 64 leaves out of 127 nodes\n",
      "INFO:tensorflow:Restoring parameters from /home/zander/thesis/vitrify/models/sdt_cnn_vae_emnist_letter/sdt_cnn_vae_emnist_letter\n",
      "Loaded sdt_cnn_vae_emnist_letter model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train SDT VAE\n",
    "sdt_vae.train(\n",
    "    x_both, y_both,\n",
    "    data[\"x_valid_flat\"], data[\"y_valid_one_hot\"], load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 62.31% | loss: 57.72686874903165\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SDT VAE\n",
    "sdt_vae_results = sdt_vae.evaluate(data[\"x_test_flat\"], data[\"y_test_one_hot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the SDT with the generated data and soft labels performed better than the SDT with only soft labels. With longer training time, it might have even outperformed the other SDT models.\n",
    "\n",
    "Now, we conduct another experiment, where we significantly downsample the original data to mimic a scenario where one does not have enough data at one's disposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_one_hot_ds  ==> (9984, 26)\n",
      "x_test_flat_ds  ==> (4992, 784)\n",
      "x_train_ds  ==> (9984, 28, 28)\n",
      "x_test_ds  ==> (4992, 28, 28)\n",
      "y_train_ds  ==> (9984,)\n",
      "y_test_one_hot_ds  ==> (4992, 26)\n",
      "y_test_ds  ==> (4992,)\n",
      "x_valid_ds  ==> (4992, 28, 28)\n",
      "y_valid_ds  ==> (4992,)\n",
      "y_valid_one_hot_ds  ==> (4992, 26)\n",
      "x_valid_flat_ds  ==> (4992, 784)\n",
      "x_train_flat_ds  ==> (9984, 784)\n"
     ]
    }
   ],
   "source": [
    "# Downsample the data\n",
    "x_train_flat_ds, y_train_ds, indices = balanced_sample_maker(data[\"x_train_flat\"], data[\"y_train\"], 10000,\n",
    "                                                             random_seed=1234)\n",
    "\n",
    "x_valid_flat_ds, y_valid_ds, indices = balanced_sample_maker(data[\"x_valid_flat\"], data[\"y_valid\"], 5000,\n",
    "                                                             random_seed=1234)\n",
    "\n",
    "x_test_flat_ds, y_test_ds, indices = balanced_sample_maker(data[\"x_test_flat\"], data[\"y_test\"], 5000,\n",
    "                                                           random_seed=1234)\n",
    "\n",
    "# Create other data\n",
    "x_train_ds = x_train_flat_ds.reshape((x_train_flat_ds.shape[0], n_rows, n_cols))\n",
    "y_train_one_hot_ds = tf.keras.utils.to_categorical(y_train_ds, n_classes)\n",
    "\n",
    "x_valid_ds = x_valid_flat_ds.reshape((x_valid_flat_ds.shape[0], n_rows, n_cols))\n",
    "y_valid_one_hot_ds = tf.keras.utils.to_categorical(y_valid_ds, n_classes)\n",
    "\n",
    "x_test_ds = x_test_flat_ds.reshape((x_test_flat_ds.shape[0], n_rows, n_cols))\n",
    "y_test_one_hot_ds = tf.keras.utils.to_categorical(y_test_ds, n_classes)\n",
    "\n",
    "# Print shapes\n",
    "print(\"y_train_one_hot_ds\", \" ==>\", np.shape(y_train_one_hot_ds))\n",
    "print(\"x_test_flat_ds\", \" ==>\", np.shape(x_test_flat_ds))\n",
    "print(\"x_train_ds\", \" ==>\", np.shape(x_train_ds))\n",
    "print(\"x_test_ds\", \" ==>\", np.shape(x_test_ds))\n",
    "print(\"y_train_ds\", \" ==>\", np.shape(y_train_ds))\n",
    "print(\"y_test_one_hot_ds\", \" ==>\", np.shape(y_test_one_hot_ds))\n",
    "print(\"y_test_ds\", \" ==>\", np.shape(y_test_ds))\n",
    "print(\"x_valid_ds\", \" ==>\", np.shape(x_valid_ds))\n",
    "print(\"y_valid_ds\", \" ==>\", np.shape(y_valid_ds))\n",
    "print(\"y_valid_one_hot_ds\", \" ==>\", np.shape(y_valid_one_hot_ds))\n",
    "print(\"x_valid_flat_ds\", \" ==>\", np.shape(x_valid_flat_ds))\n",
    "print(\"x_train_flat_ds\", \" ==>\", np.shape(x_train_flat_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have created new data variables, each appended with \"ds\". We will now use these variables and repeat the _vitrify_ process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Train the VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we start off by initialising the VAE model. Note the name change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear our current Keras session\n",
    "K.clear_session()\n",
    "\n",
    "# Create VAE\n",
    "vae = VariationalAutoEncoder(\n",
    "    name = \"vae_emnist_letter_ds\",\n",
    "    num_inputs = n_features,\n",
    "    # If true, training info is outputted to stdout\n",
    "    keras_verbose = False,\n",
    "    # A summary of the NN is printed to stdout\n",
    "    print_model_summary = False,\n",
    "    # Size of latent dimension\n",
    "    latent_dim = 20,\n",
    "    # Specify the encoder layers [units, activation, dropout, l2, bias]\n",
    "    encoder_layers = [\n",
    "        [512, \"relu\", 0.0, 0.0, True, \"gaussian\"],\n",
    "        [256, \"relu\", 0.0, 0.0, True, \"gaussian\"],\n",
    "        [128, \"relu\", 0.0, 0.0, True, \"gaussian\"]\n",
    "    ],\n",
    "    # Specify the decoder layers [units, activation, dropout, l2, bias]\n",
    "    decoder_layers = [\n",
    "        [128, \"relu\", 0.0, 0.0, True, \"gaussian\"],\n",
    "        [256, \"relu\", 0.0, 0.0, True, \"gaussian\"],\n",
    "        [512, \"relu\", 0.0, 0.0, True, \"gaussian\"]\n",
    "    ],\n",
    "    # The final output layer's activation function\n",
    "    final_activation = \"sigmoid\",\n",
    "    # The maximum number of epochs to run\n",
    "    epochs = 100,\n",
    "    # The batch size to use in the VAE\n",
    "    batch_size = 128,\n",
    "    # The learning rate used in optimisation\n",
    "    learning_rate = 0.001,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vae_emnist_letter_ds model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train VAE\n",
    "vae.train(x_train_flat_ds, x_valid_flat_ds, load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: Nan | loss: 169.49714709550906\n"
     ]
    }
   ],
   "source": [
    "# Evaluate VAE\n",
    "vae_results = vae.evaluate(x_test_flat_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our trained VAE model, we can generate new data. Here we generate 40000 additional data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Generate new data\n",
    "x_gen_flat = vae.sample(40000)\n",
    "print(np.shape(x_gen_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Reshape to images\n",
    "x_gen = np.array([np.reshape(x_gen_flat[i], [n_rows, n_cols]) for i in range(len(x_gen_flat))])\n",
    "print(np.shape(x_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN\n",
    "cnn = ConvDNN(\n",
    "    name = \"cnn_emnist_letter_ds\",\n",
    "    img_rows = n_rows,\n",
    "    img_cols = n_cols,\n",
    "    num_outputs = n_classes,\n",
    "    # If true, training info is outputted to stdout\n",
    "    keras_verbose = False,\n",
    "    # A summary of the NN is printed to stdout\n",
    "    print_model_summary = False,\n",
    "    # Convolutional layers\n",
    "    conv_layers = [\n",
    "        # Layer, filters, kernel size, strides, padding, activation, use bias, kernel reg, bias reg, activity reg,\n",
    "        # dropout (after layers)\n",
    "            [\"conv2d\", 64, (3, 3), (1, 1), \"valid\", \"relu\", True, 0.0, 0.0, 0.0, 0.2],\n",
    "            [\"conv2d\", 64, (3, 3), (1, 1), \"valid\", \"relu\", True, 0.0, 0.0, 0.0, 0.2],\n",
    "            [\"max_pool2d\", (2, 2), None, \"valid\", 0.0],\n",
    "            [\"conv2d\", 64, (3, 3), (1, 1), \"valid\", \"relu\", True, 0.0, 0.0, 0.0, 0.2],\n",
    "            [\"conv2d\", 64, (3, 3), (1, 1), \"valid\", \"relu\", True, 0.0, 0.0, 0.0, 0.2],\n",
    "            [\"max_pool2d\", (2, 2), None, \"valid\", 0.0]\n",
    "    ],\n",
    "    # ff_layers = [units, activation, regularization, dropout, use_bias]\n",
    "    ff_layers = [\n",
    "        [512, \"relu\", 0.0, 0.2, True, \"normal\"],\n",
    "        [512, \"relu\", 0.0, 0.2, True, \"normal\"]\n",
    "    ],\n",
    "    # The final output layer's activation function\n",
    "    final_activation = \"softmax\",\n",
    "    # The objective function for the NN\n",
    "    objective = \"categorical_crossentropy\",\n",
    "    # The maximum number of epochs to run\n",
    "    epochs = 20,\n",
    "    # The batch size to use in the NN\n",
    "    batch_size = 128,\n",
    "    # The learning rate used in optimization\n",
    "    learning_rate = 0.001,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CNN model, we do not use the flattenend training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cnn_emnist_letter_ds model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train CNN\n",
    "cnn.train(\n",
    "    x_train_ds, y_train_one_hot_ds,\n",
    "    x_valid_ds, y_valid_one_hot_ds, load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.59% | loss: 0.28389772256979573\n"
     ]
    }
   ],
   "source": [
    "# Evaluate CNN\n",
    "cnn_results = cnn.evaluate(x_test_ds, y_test_one_hot_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Produce soft targets for our interpretable model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use our trained CNN model to:\n",
    "1. Relabel our original training data, **x_train_ds**\n",
    "2. Give labels to our unlabelled, generated data, **x_gen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CNN labels\n",
    "y_cnn_train = cnn.predict(x_train_ds)\n",
    "y_gen = cnn.predict(x_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine both the original training data and the generated data, as well as their new soft target labels, and shuffle them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_both ==> (49984, 784)\n",
      "y_both ==> (49984, 26)\n"
     ]
    }
   ],
   "source": [
    "# Combine x_train and x_gen\n",
    "x_both = join_data([x_train_ds, x_gen])\n",
    "\n",
    "# Flatten them to use it with our interpretable model\n",
    "x_both = x_both.reshape((x_both.shape[0], -1))\n",
    "\n",
    "# Combine y_cnn_train and y_gen\n",
    "y_both = join_data([y_cnn_train, y_gen])\n",
    "\n",
    "# Shuffle the data\n",
    "x_both, y_both = shuffle(x_both, y_both)\n",
    "\n",
    "print(\"x_both ==>\", np.shape(x_both))\n",
    "print(\"y_both ==>\", np.shape(y_both))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have increased our training data to 49984, where each sample now has a soft target produced from the CNN model, which we are going to approximate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Train our interpretable model, the SDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) SDT using only the original data with original hard targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SDT\n",
    "sdt_raw = SoftBinaryDecisionTree(\n",
    "    name = \"sdt_raw_emnist_letter_ds\",\n",
    "    num_inputs = n_features,\n",
    "    num_outputs = n_classes,\n",
    "    # If true, training info is outputted to stdout\n",
    "    keras_verbose = False,\n",
    "    # A summary of the NN is printed to stdout\n",
    "    print_model_summary = False,\n",
    "    # Hyperparameters\n",
    "    max_depth = 5,\n",
    "    penalty_strength = 1e+1,\n",
    "    penalty_decay = 0.5,\n",
    "    inv_temp = 0.01,\n",
    "    ema_win_size = 1000,\n",
    "    # The learning rate used in optimization\n",
    "    learning_rate = 1e-03,\n",
    "    epochs = 40,\n",
    "    batch_size = 4,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built tree has 32 leaves out of 63 nodes\n",
      "INFO:tensorflow:Restoring parameters from /home/zander/thesis/vitrify/models/sdt_raw_emnist_letter_ds/sdt_raw_emnist_letter_ds\n",
      "Loaded sdt_raw_emnist_letter_ds model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train SDT RAW\n",
    "sdt_raw.train(\n",
    "    x_train_flat_ds, y_train_one_hot_ds,\n",
    "    x_valid_flat_ds, y_valid_one_hot_ds, load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 31.15% | loss: 40.83087239815639\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SDT RAW\n",
    "sdt_raw_results = sdt_raw.evaluate(x_test_flat_ds, y_test_one_hot_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) SDT using only the original data with new soft targets (provided by the CNN in the third stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SDT CNN\n",
    "sdt_cnn = SoftBinaryDecisionTree(\n",
    "    name = \"sdt_cnn_emnist_letter_ds\",\n",
    "    num_inputs = n_features,\n",
    "    num_outputs = n_classes,\n",
    "    # If true, training info is outputted to stdout\n",
    "    keras_verbose = False,\n",
    "    # A summary of the NN is printed to stdout\n",
    "    print_model_summary = False,\n",
    "    # Hyperparameters\n",
    "    max_depth = 5,\n",
    "    penalty_strength = 1e+1,\n",
    "    penalty_decay = 0.5,\n",
    "    inv_temp = 0.01,\n",
    "    ema_win_size = 1000,\n",
    "    # The learning rate used in optimization\n",
    "    learning_rate = 1e-03,\n",
    "    epochs = 40,\n",
    "    batch_size = 4,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built tree has 32 leaves out of 63 nodes\n",
      "INFO:tensorflow:Restoring parameters from /home/zander/thesis/vitrify/models/sdt_cnn_emnist_letter_ds/sdt_cnn_emnist_letter_ds\n",
      "Loaded sdt_cnn_emnist_letter_ds model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train SDT CNN\n",
    "sdt_cnn.train(\n",
    "    x_train_flat_ds, y_cnn_train,\n",
    "    x_valid_flat_ds, y_valid_one_hot_ds, load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 28.85% | loss: 36.14033850645408\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SDT CNN\n",
    "sdt_cnn_results = sdt_cnn.evaluate(x_test_flat_ds, y_test_one_hot_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) SDT using the generated and the original data with soft targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SDT VAE\n",
    "sdt_vae = SoftBinaryDecisionTree(\n",
    "    name = \"sdt_cnn_vae_emnist_letter_ds\",\n",
    "    num_inputs = n_features,\n",
    "    num_outputs = n_classes,\n",
    "    # If true, training info is outputted to stdout\n",
    "    keras_verbose = False,\n",
    "    # A summary of the NN is printed to stdout\n",
    "    print_model_summary = False,\n",
    "    # Hyperparameters\n",
    "    max_depth = 5,\n",
    "    penalty_strength = 1e+1,\n",
    "    penalty_decay = 0.5,\n",
    "    inv_temp = 0.01,\n",
    "    ema_win_size = 1000,\n",
    "    # The learning rate used in optimization\n",
    "    learning_rate = 1e-03,\n",
    "    epochs = 40,\n",
    "    batch_size = 4,\n",
    "    # If this many stagnant epochs are seen, stop training\n",
    "    stopping_patience = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built tree has 32 leaves out of 63 nodes\n",
      "INFO:tensorflow:Restoring parameters from /home/zander/thesis/vitrify/models/sdt_cnn_vae_emnist_letter_ds/sdt_cnn_vae_emnist_letter_ds\n",
      "Loaded sdt_cnn_vae_emnist_letter_ds model from disk\n"
     ]
    }
   ],
   "source": [
    "# Train SDT VAE\n",
    "sdt_vae.train(\n",
    "    x_both, y_both,\n",
    "    x_valid_flat_ds, y_valid_one_hot_ds, load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 48.32% | loss: 35.659014814939255\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SDT VAE\n",
    "sdt_vae_results = sdt_vae.evaluate(x_test_flat_ds, y_test_one_hot_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classification problem was too complex for our SDT models to adequately capture the underlying phenomenon. We do see, however, that the addition of generated data and soft labels did help the SDT model. In terms of inter- pretability, it was clear that the SDT models struggle to distinguish between classes, with the added difficulty of classifying upper- and lowercase letters simultaneously. With a depth of 6, the visualisations became unfeasible to plot. Classifying, for example, an “a” and “A” to the same label (i.e. 0), made the problem too hard for our SDT models. We decided to reduce the problem to only distinguishing among uppercase letters, by removing all the lowercase letters. This can be seen in the *vitrify_emnist_letter_uppercase.ipynb* notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
